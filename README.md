# Hybrid Retrieval-Augmented Generation (RAG) System

## **Overview**
This repository presents a solution for building a **Retrieval-Augmented Generation (RAG)** system. The objective is to answer questions from a textbook while providing concise and context-aware responses, supported by verifiable references to sections and pages.

---

## **Solution Highlights**
### **Hybrid Retriever**
- **Dense Retrieval**:
  - Efficient similarity search using **FAISS** and **SentenceTransformer embeddings**.
- **Sparse Retrieval**:
  - Keyword-based search using **BM25**.
- **Hybrid Scoring**:
  - Weighted combination of dense and sparse scores:
    ```python
    hybrid_score = (dense_weight * dense_score) + ((1 - dense_weight) * sparse_score)
    ```
- **Re-Ranking**:
  - Top candidates refined using a **Cross-Encoder** for improved relevance.

### **Generative Model**
- **Answer Generation**:
  - Generates concise, context-aware answers using **Qwen2.5-0.5B**.

### **Reference Extraction**
- Provides supporting **sections** and **page numbers** for each generated answer to ensure transparency and traceability.

---

## **Implementation**

### **Hybrid Retrieval**
1. **Dense Retrieval**:
   - Uses FAISS for efficient similarity search with embeddings generated by **SentenceTransformer**.
2. **Sparse Retrieval**:
   - Relies on BM25 for keyword-based matching.
3. **Hybrid Scoring**:
   - Combines dense and sparse scores for optimal retrieval results.
4. **Re-Ranking**:
   - Utilizes a Cross-Encoder (e.g., `cross-encoder/ms-marco-MiniLM-L-12-v2`) to refine the top retrieved contexts.

### **RAG Pipeline**
1. **Context Retrieval**:
   - Fetches relevant sections using the hybrid retriever.
2. **Answer Generation**:
   - Generates answers with context using the **Qwen2.5-0.5B** model.
3. **Reference Extraction**:
   - Outputs relevant section and page references for verification.

### **Fine-Tuning (Optional)**
- **Sentence Embeddings**:
  - Can be fine-tuned for domain-specific data using `MultipleNegativesRankingLoss` from **SentenceTransformers**.

---

## **Workflow**
1. **Load and preprocess the textbook data**.
2. **Perform Hybrid Retrieval** with the `HybridRetriever` class.
3. **Generate answers** with retrieved context using the generative model.
4. **Output results** to a CSV file with the following format:
   - `ID`: Query ID.
   - `Context`: Retrieved sections.
   - `Answer`: Model-generated answer.
   - `References`: JSON containing section and page details.

---

## **References**
### **Data**
- Textbook: Open-source textbook for psychology.

### **Models**
- **Sentence Embeddings**: `all-mpnet-base-v2`
- **Cross-Encoder**: `cross-encoder/ms-marco-MiniLM-L-12-v2`
- **Generative Model**: `Qwen2.5-0.5B`

---

## **How to Use**
1. Clone the repository.
2. Install the required dependencies.
3. Run the provided script to load the textbook data and process queries.
4. Fine-tune embeddings if necessary for better domain adaptation.

---
